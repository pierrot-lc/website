---
title: PhD journal entry
date: 2025-09-09
---

So [PAISS](https://paiss.inria.fr) went well. It was the first time I got to be around so many PhD
students doing the same thing as me. All those people were friendly and open to discuss about
anything. A lot of them were also curious about my poster, which felt great! I was surprised to see
how little people knew about transformers and their modern positional encoding. I realised I'm still
in a bubble. To be fair, I knew nothing about most of others' papers.

Presentations were also very good, and of course I got to met Yann LeCun!!! Sadly it was impossible
to discuss with him directly, I should have asked questions after his talk. Maybe I should send that
email? Other than him, a lot of talks were highly interesting. I'd like to learn more about this
[Optimal Transport thing](https://arxiv.org/abs/2505.06589).

It also opened my horizons for the next projects I'd like to do:
- Learn a neural solver that generates a TSP solution in one pass. It should directly predicts the
  permutation matrix. The issue I had was with the decoding of this permutation matrix: doing it
  step by step greedily would of course be suboptimal because ideally probabilities should adapt to
  what's been already decoded in the partial solution. It also would make the solution dependant on
  a starting point, which is really not what we want if we can predict everything at once. So the
  best thing to do is probably to use the [linear assignment problem](https://optax.readthedocs.io/en/latest/_collections/examples/linear_assignment_problem.html)
  and maximize the total probability of the matrix. Thanks
  [Adrien](https://www.linkedin.com/in/adrien-lagesse-18b1211b9/) for the suggestion and
  explanations! Combine this with a powerful architecture (EBMs??).
- Another line of work would be to do this never-ending neural local search. But I tried it already
  and got very bad results, mainly because it is a hard setup for RL: a lot of actions, possibility
  to go back to previous states, infinite horizon... So when I asked about what I could do about it,
  [Claire](https://www.cvernade.com/) pointed me toward [Average Reward RL](https://web.ics.purdue.edu/~vaneet/publi_avrl.htm).
  It looks like a very promising way to handle my problem! I am still a little bit afraid about how
  search is handled in such environments with many actions and infinite horizon.

I am now back to Sophia-Antipolis. And I realised I have to prepare the class for next week. My
paper isn't ready. Another stressful week again. In about 10 days I will have to submit it, and I'll
be going on vacations for two weeks I think. It's going to be great.
